{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d354da73",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b3fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97e648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# declaring global font size for plots:\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc268c8",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce34b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                                                         Non-Null Count  Dtype  \n",
      "---  ------                                                                         --------------  -----  \n",
      " 0   start MTU (UTC)                                                                8760 non-null   object \n",
      " 1   Day-ahead Price [EUR/MWh] BZN|NO1                                              8760 non-null   float64\n",
      " 2   Day-ahead Price [EUR/MWh] BZN|NO3                                              8760 non-null   float64\n",
      " 3   Day-ahead Price [EUR/MWh] BZN|NO5                                              8760 non-null   float64\n",
      " 4   Day-ahead Price [EUR/MWh] BZN|SE3                                              8760 non-null   float64\n",
      " 5   Actual Total Load [MW] - BZN|NO5                                               8760 non-null   float64\n",
      " 6   Hydro Run-of-river and poundage - BZN|NO1                                      8760 non-null   float64\n",
      " 7   Hydro Water Reservoir - BZN|NO1                                                8760 non-null   float64\n",
      " 8   Wind Onshore - BZN|NO1                                                         8760 non-null   float64\n",
      " 9   Hydro Pumped Storage Aggregated- BZN|NO2                                       8760 non-null   float64\n",
      " 10  Hydro Run-of-river and poundage - BZN|NO2                                      8760 non-null   float64\n",
      " 11  Hydro Water Reservoir - BZN|NO2                                                8760 non-null   float64\n",
      " 12  Waste - BZN|NO2                                                                8760 non-null   float64\n",
      " 13  Wind Onshore - BZN|NO2                                                         8760 non-null   float64\n",
      " 14  Hydro Pumped Storage Aggregated- BZN|NO3                                       8760 non-null   float64\n",
      " 15  Hydro Run-of-river and poundage - BZN|NO3                                      8760 non-null   float64\n",
      " 16  Hydro Water Reservoir - BZN|NO3                                                8760 non-null   float64\n",
      " 17  Other renewable - BZN|NO3                                                      8760 non-null   float64\n",
      " 18  Wind Onshore - BZN|NO3                                                         8760 non-null   float64\n",
      " 19  Fossil Gas - BZN|NO5                                                           8760 non-null   float64\n",
      " 20  Hydro Pumped Storage Aggregated- BZN|NO5                                       8760 non-null   float64\n",
      " 21  Hydro Run-of-river and poundage - BZN|NO5                                      8760 non-null   float64\n",
      " 22  Waste - BZN|NO5                                                                8760 non-null   float64\n",
      " 23  Hydro Water Reservoir - BZN|SE3                                                8760 non-null   float64\n",
      " 24  Nuclear - BZN|SE3                                                              8760 non-null   float64\n",
      " 25  Solar - BZN|SE3                                                                8760 non-null   float64\n",
      " 26  Wind Onshore - BZN|SE3                                                         8760 non-null   float64\n",
      " 27  CBF BZN|NO2 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 28  CBF BZN|NO1 > BZN|NO2 [MW]                                                     8760 non-null   float64\n",
      " 29  CBF BZN|NO3 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 30  CBF BZN|NO1 > BZN|NO3 [MW]                                                     8760 non-null   float64\n",
      " 31  CBF BZN|NO5 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 32  CBF BZN|NO1 > BZN|NO5 [MW]                                                     8760 non-null   float64\n",
      " 33  CBF BZN|SE3 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 34  CBF BZN|NO1 > BZN|SE3 [MW]                                                     8760 non-null   float64\n",
      " 35  Stored Energy Value Water Reservoirs and Hydro Storage Plants [MWh] - BZN|NO3  8760 non-null   float64\n",
      " 36  Stored Energy Value Water Reservoirs and Hydro Storage Plants [MWh] - BZN|SE3  8760 non-null   float64\n",
      "dtypes: float64(36), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../datasets/complete_data/df.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d31436",
   "metadata": {},
   "source": [
    "The datatype of the datetime column \"start MTU (UTC)\" is object, so we need to convert it into a datetime object. We then need to set the \"start MTU (UTC)\" column as the index, which is required for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3d2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime\n",
    "df['start MTU (UTC)'] = pd.to_datetime(df['start MTU (UTC)'])\n",
    "\n",
    "# Set the date column as the index\n",
    "df.set_index('start MTU (UTC)', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b680239",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51290057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (7008, 36)\n",
      "Validation set shape: (876, 36)\n",
      "Test set shape: (876, 36)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "# shuffle is set to false so that the order of the data is maintained\n",
    "train, test_valid = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "valid, test = train_test_split(test_valid, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Print the shapes of the train, valid, and test sets\n",
    "print(\"Train set shape:\", train.shape)\n",
    "print(\"Validation set shape:\", valid.shape)\n",
    "print(\"Test set shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea4dda",
   "metadata": {},
   "source": [
    "## Creating a lagged dataset with 24 lag features for each input feature\n",
    "\n",
    "When predicting time series, it is important to consider the temporal relationship between observations. Since the observations over time are not independent of each other, we cannot simply use all of the data to train our model as we would in a typical machine learning problem. Instead, we typically create a \"lagged\" dataset that contains the predictors and the target variable for each time step. This lagged dataset is used to train our model.\n",
    "\n",
    "To create a lagged dataset, we shift the target variable forward by one or more time steps, using the resulting series as the target variable for that time step. We also include the values of the predictors at the previous time steps as features. This way, the model can learn to use past predictor values to predict future target variable values.\n",
    "\n",
    "For instance, for hourly data and a prediction horizon of 24 hours, we would create a lagged dataset where each row contains the predictors and the target variable for a specific hour. The target variable for each row would be the value 24 hours in the future, and the predictors for each row would be the values of the predictors for the previous 24 hours. This lagged dataset would then be used to train our model to make predictions for the next 24 hours.\n",
    "\n",
    "By shifting the target feature forward by one period, we create a dataset where each observation includes the past observations up to the previous period and the target variable value for the next period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543d0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create lagged dataset wit 24 lag features for each input feature\n",
    "def create_lagged_dataset(df):\n",
    "    # creating a copy of the dataframe\n",
    "    lagged_df = df.copy()\n",
    "    \n",
    "    # Adding lagged features for target variable\n",
    "    lagged_df['Day-ahead Price [EUR/MWh] BZN|NO1'] = lagged_df['Day-ahead Price [EUR/MWh] BZN|NO1'].shift(-1)\n",
    "    \n",
    "    # Dropping the last row containing NaN values\n",
    "    lagged_df.dropna(inplace=True)\n",
    "    \n",
    "    # Creating a dataframe with lagged features with 24 steps for each of the original features\n",
    "    lagged_df = pd.concat([lagged_df.shift(i) for i in range(24)], axis=1)\n",
    "    \n",
    "    # Removing the NaN rows that have been created in the beginning of the dataset\n",
    "    lagged_df.dropna(inplace=True)\n",
    "    \n",
    "    return lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35b7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lagged dataset for train and test dataset\n",
    "lagged_train = create_lagged_dataset(train)\n",
    "lagged_valid = create_lagged_dataset(valid)\n",
    "lagged_test = create_lagged_dataset(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6012b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  (6984, 840) (6984, 24)\n",
      "Validation Data Shape:  (852, 840) (852, 24)\n",
      "Test Data Shape:  (852, 840) (852, 24)\n"
     ]
    }
   ],
   "source": [
    "# separating the target feature and the input features\n",
    "train_y = lagged_train['Day-ahead Price [EUR/MWh] BZN|NO1']\n",
    "train_x = lagged_train.drop(['Day-ahead Price [EUR/MWh] BZN|NO1'], axis=1)\n",
    "\n",
    "valid_y = lagged_valid['Day-ahead Price [EUR/MWh] BZN|NO1']\n",
    "valid_x = lagged_valid.drop(['Day-ahead Price [EUR/MWh] BZN|NO1'], axis=1)\n",
    "\n",
    "test_y = lagged_test['Day-ahead Price [EUR/MWh] BZN|NO1']\n",
    "test_x = lagged_test.drop(['Day-ahead Price [EUR/MWh] BZN|NO1'], axis=1)\n",
    "\n",
    "#print the shapes of the datasets\n",
    "print(\"Train Data Shape: \", train_x.shape, train_y.shape)\n",
    "print(\"Validation Data Shape: \", valid_x.shape, valid_y.shape)\n",
    "print(\"Test Data Shape: \", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710de04",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f1f64d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 540.93 seconds\n",
      "Mean absolute error:             20.970617397406194\n",
      "Mean absolute percentage error:  0.08930201861731757\n",
      "Mean squared error:              926.6677191806621\n",
      "Rood mean squared error:         30.44121743920013\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(train_x, train_y)\n",
    "# stop timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Make predictions on the test data\n",
    "pred_y = rf.predict(test_x)\n",
    "\n",
    "\n",
    "#print the run time\n",
    "print(\"Runtime: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Calculate the mean absolute error (MAE) between the predicted and actual values\n",
    "mae = mean_absolute_error(test_y, pred_y)\n",
    "print(\"Mean absolute error:            \", mae)\n",
    "\n",
    "# Calculate the mean absolute percentage error (MAE) between the predicted and actual values\n",
    "mape = mean_absolute_percentage_error(test_y, pred_y)\n",
    "print(\"Mean absolute percentage error: \", mape)\n",
    "\n",
    "# Calculating the mean squared error (MSE) between the predicted and actual values\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"Mean squared error:             \", mse)\n",
    "\n",
    "# Calculating the root mean squared error (RMSE) between the predicted and actual values\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"Rood mean squared error:        \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b2002",
   "metadata": {},
   "source": [
    "## Plotting mean of predicted vs mean of actual values for the base rf model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "# Plot the mean of the actual and predicted values\n",
    "plt.plot(test_y.index, np.mean(test_y, axis=1), label='Actual')\n",
    "plt.plot(test_y.index, np.mean(pred_y, axis=1), label='Predicted')\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Mean of Actual vs mean of Predicted Day-ahead Price [EUR/MWh] BZN|NO1')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price [EUR/MWh]')\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad09c96",
   "metadata": {},
   "source": [
    "### NB! this is direct copy, needs to be rewritten!\n",
    "In terms of MAPE, a commonly used benchmark is a value less than 10%. However, this can vary depending on the specific industry and application. For example, in finance, a MAPE less than 2% may be considered good.\n",
    "\n",
    "For RMSE, a good value depends on the scale of the data being analyzed. A common practice is to compare the RMSE to the range of the target variable. As a rough guideline, an RMSE that is less than 10% of the range of the target variable can be considered good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b62db1",
   "metadata": {},
   "source": [
    "## hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ca4e1",
   "metadata": {},
   "source": [
    "To handle the time series nature of the data, rolling origin cross-validation is used, which involves training the model on a rolling window of historical data and testing it on the next observation. The primary benefit of using the rolling origin cross-validation method is that it maintains the temporal order of the data, which is essential for accurate time series forecasting. This approach ensures that the model is evaluated on data that is more similar to the future data it will be predicting.\n",
    "\n",
    "A random search is performed on a dictionary of hyperparameters to search for the best combination of hyperparameters for the random forest regressor model. The hyperparameters tuned in this process include the number of trees in the forest (n_estimators), the maximum depth of each tree (max_depth), the minimum number of samples required to split an internal node (min_samples_split), the minimum number of samples required to be at a leaf node (min_samples_leaf), and the maximum number of features to consider when looking for the best split (max_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a random forest regressor object\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Define a dictionary of hyperparameters to search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize lists to store the performance metrics\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "mape_scores = []\n",
    "mse_scores = []\n",
    "\n",
    "# Perform rolling origin cross-validation\n",
    "for i in range(n_folds, len(valid_y)):\n",
    "    # Split the data into training and validation sets\n",
    "    train_y = valid_y.iloc[i-n_folds:i]\n",
    "    train_x = valid_x.iloc[i-n_folds:i]\n",
    "    val_y = valid_y.iloc[i:i+1]\n",
    "    val_x = valid_x.iloc[i:i+1]\n",
    "\n",
    "    # Perform a random search on the training data\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1, random_state=0, scoring='neg_mean_squared_error')\n",
    "    random_search.fit(train_x, train_y)\n",
    "\n",
    "    # Extract the best model from the random search\n",
    "    best_rf_model = random_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the validation data using the best model\n",
    "    val_predictions = best_rf_model.predict(val_x)\n",
    "\n",
    "    # Calculate the performance metrics for the current fold\n",
    "    rmse_scores.append(math.sqrt(mean_squared_error(val_y, val_predictions)))\n",
    "    mae_scores.append(mean_absolute_error(val_y, val_predictions))\n",
    "    mape_scores.append(mean_absolute_percentage_error(val_y, val_predictions))\n",
    "    mse_scores.append(mean_squared_error(val_y, val_predictions))\n",
    "\n",
    "# stop timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime\n",
    "print(\"Runtime: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Print the average performance metrics over all folds\n",
    "print(\"Average Mean Absolute Error (MAE):\", round(np.mean(mae_scores), 2))\n",
    "print(\"Average Mean Absolute Percentage Error (MAPE):\", round(np.mean(mape_scores), 2), \"%\")\n",
    "print(\"Average Mean Squared Error (MSE):\", round(np.mean(mse_scores), 2))\n",
    "print(\"Average Root Mean Squared Error (RMSE):\", round(np.mean(rmse_scores), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6907f87",
   "metadata": {},
   "source": [
    "## Plotting mean of predicted vs mean of actual values for the best rf model with validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimal hyperparameters found through grid search\n",
    "optimal_params = random_search.best_params_\n",
    "\n",
    "# Create a random forest regressor object with the optimal hyperparameters\n",
    "rf = RandomForestRegressor(**optimal_params, random_state=0)\n",
    "\n",
    "# Train the model on the validation data\n",
    "rf.fit(valid_x, valid_y)\n",
    "\n",
    "# Make predictions on the validation data using the trained model\n",
    "val_predictions = rf.predict(valid_x)\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot the mean of the actual and predicted values\n",
    "plt.plot(test_y.index, np.mean(test_y, axis=1), label='Actual')\n",
    "plt.plot(test_y.index, np.mean(test_pred_y, axis=1), label='Predicted')\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Mean of Actual vs mean of Predicted Day-ahead Price [EUR/MWh] BZN|NO1')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price [EUR/MWh]')\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241ca38",
   "metadata": {},
   "source": [
    "In order to assess the performance of the model with the optimal hyperparameters on the test data, we must first train the model on the combined training and validation data using the tuned hyperparameters obtained from the cross-validation grid search. After training the model, we can use it to make predictions on the test data and measure its performance using the same metrics (MAE, MAPE, MSE, and RMSE) that were used to evaluate its performance on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training and validation data\n",
    "train_x = pd.concat([train_x, valid_x])\n",
    "train_y = pd.concat([train_y, valid_y])\n",
    "\n",
    "# Define the optimal hyperparameters found through grid search\n",
    "optimal_params = random_search.best_params_\n",
    "\n",
    "# Create a random forest regressor object with the optimal hyperparameters\n",
    "rf = RandomForestRegressor(**optimal_params, random_state=0)\n",
    "\n",
    "# Train the model on the combined training and validation data\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "# Make predictions on the test data using the trained model\n",
    "test_pred_y = rf.predict(test_x)\n",
    "\n",
    "# Evaluate the performance of the model on the test data using the same metrics used for validation data\n",
    "test_rmse = math.sqrt(mean_squared_error(test_y, test_pred_y))\n",
    "test_mae = mean_absolute_error(test_y, test_pred_y)\n",
    "test_mape = mean_absolute_percentage_error(test_y, test_pred_y)\n",
    "test_mse = mean_squared_error(test_y, test_pred_y)\n",
    "\n",
    "# Print the performance metrics on the test data\n",
    "print(\"Root Mean Squared Error on Test Data:\", round(test_rmse, 2))\n",
    "print(\"Mean Absolute Error on Test Data:\", round(test_mae, 2))\n",
    "print(\"Mean Absolute Percentage Error on Test Data:\", round(test_mape, 2))\n",
    "print(\"Mean Squared Error on Test Data:\", round(test_mse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff5dad",
   "metadata": {},
   "source": [
    "## Plotting mean of predicted vs mean of actual values for the best rf model with test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bf6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot the mean of the actual and predicted values\n",
    "plt.plot(test_y.index, np.mean(test_y, axis=1), label='Actual')\n",
    "plt.plot(test_y.index, np.mean(test_pred_y, axis=1), label='Predicted')\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Mean of Actual vs mean of Predicted Day-ahead Price [EUR/MWh] BZN|NO1')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price [EUR/MWh]')\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d10a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d876129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
