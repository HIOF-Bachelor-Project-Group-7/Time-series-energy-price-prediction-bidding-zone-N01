{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d354da73",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b3fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc268c8",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce34b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 40 columns):\n",
      " #   Column                                                                         Non-Null Count  Dtype  \n",
      "---  ------                                                                         --------------  -----  \n",
      " 0   start MTU (UTC)                                                                8760 non-null   object \n",
      " 1   Day-ahead Price [EUR/MWh] BZN|NO1                                              8760 non-null   float64\n",
      " 2   Day-ahead Price [EUR/MWh] BZN|NO3                                              8760 non-null   float64\n",
      " 3   Day-ahead Price [EUR/MWh] BZN|NO5                                              8760 non-null   float64\n",
      " 4   Day-ahead Price [EUR/MWh] BZN|SE3                                              8760 non-null   float64\n",
      " 5   Actual Total Load [MW] - BZN|NO5                                               8760 non-null   float64\n",
      " 6   Actual Total Load [MW] - BZN|SE3                                               8760 non-null   float64\n",
      " 7   Hydro Run-of-river and poundage - BZN|NO1                                      8760 non-null   float64\n",
      " 8   Hydro Water Reservoir - BZN|NO1                                                8760 non-null   float64\n",
      " 9   Wind Onshore - BZN|NO1                                                         8760 non-null   float64\n",
      " 10  Hydro Pumped Storage Aggregated- BZN|NO2                                       8760 non-null   float64\n",
      " 11  Hydro Run-of-river and poundage - BZN|NO2                                      8760 non-null   float64\n",
      " 12  Hydro Water Reservoir - BZN|NO2                                                8760 non-null   float64\n",
      " 13  Waste - BZN|NO2                                                                8760 non-null   float64\n",
      " 14  Wind Onshore - BZN|NO2                                                         8760 non-null   float64\n",
      " 15  Hydro Pumped Storage Aggregated- BZN|NO3                                       8760 non-null   float64\n",
      " 16  Hydro Run-of-river and poundage - BZN|NO3                                      8760 non-null   float64\n",
      " 17  Hydro Water Reservoir - BZN|NO3                                                8760 non-null   float64\n",
      " 18  Other renewable - BZN|NO3                                                      8760 non-null   float64\n",
      " 19  Waste - BZN|NO3                                                                8760 non-null   float64\n",
      " 20  Wind Onshore - BZN|NO3                                                         8760 non-null   float64\n",
      " 21  Fossil Gas - BZN|NO5                                                           8760 non-null   float64\n",
      " 22  Hydro Pumped Storage Aggregated- BZN|NO5                                       8760 non-null   float64\n",
      " 23  Hydro Run-of-river and poundage - BZN|NO5                                      8760 non-null   float64\n",
      " 24  Waste - BZN|NO5                                                                8760 non-null   float64\n",
      " 25  Hydro Water Reservoir - BZN|SE3                                                8760 non-null   float64\n",
      " 26  Nuclear - BZN|SE3                                                              8760 non-null   float64\n",
      " 27  Other - BZN|SE3                                                                8760 non-null   float64\n",
      " 28  Solar - BZN|SE3                                                                8760 non-null   float64\n",
      " 29  Wind Onshore - BZN|SE3                                                         8760 non-null   float64\n",
      " 30  CBF BZN|NO2 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 31  CBF BZN|NO1 > BZN|NO2 [MW]                                                     8760 non-null   float64\n",
      " 32  CBF BZN|NO3 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 33  CBF BZN|NO1 > BZN|NO3 [MW]                                                     8760 non-null   float64\n",
      " 34  CBF BZN|NO5 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 35  CBF BZN|NO1 > BZN|NO5 [MW]                                                     8760 non-null   float64\n",
      " 36  CBF BZN|SE3 > BZN|NO1 [MW]                                                     8760 non-null   float64\n",
      " 37  CBF BZN|NO1 > BZN|SE3 [MW]                                                     8760 non-null   float64\n",
      " 38  Stored Energy Value Water Reservoirs and Hydro Storage Plants [MWh] - BZN|NO5  8760 non-null   float64\n",
      " 39  Stored Energy Value Water Reservoirs and Hydro Storage Plants [MWh] - BZN|SE3  8760 non-null   float64\n",
      "dtypes: float64(39), object(1)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../datasets/complete_data/df.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d31436",
   "metadata": {},
   "source": [
    "The datatype of the datetime column \"start MTU (UTC)\" is object, so we need to convert it into a datetime object. We then need to set the \"start MTU (UTC)\" column as the index, which is required for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3d2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime\n",
    "df['start MTU (UTC)'] = pd.to_datetime(df['start MTU (UTC)'])\n",
    "\n",
    "# Set the date column as the index\n",
    "df.set_index('start MTU (UTC)', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b680239",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51290057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "# shuffle is set to false so that the ordinality of the data is maintained\n",
    "train, test = train_test_split(df, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea4dda",
   "metadata": {},
   "source": [
    "## Creating a lagged dataset with 24 lag features for each input feature\n",
    "\n",
    "### NB! this is direct copy, needs to be rewritten!\n",
    "When we want to make time series predictions, we need to consider the temporal relationship between the observations. In other words, we need to take into account the fact that each observation is measured at a particular time and that the observations over time are not independent of each other. Therefore, we can't simply use all of the data to train our model, as we would in a typical machine learning problem.\n",
    "\n",
    "Instead, we typically create a \"lagged\" dataset where each row contains the predictors and the target variable for a particular time step. We use this lagged dataset to train our model. To create this lagged dataset, we shift the target variable forward by one or more time steps and use the resulting series as the target variable for that time step. We also include the values of the predictors at the previous time steps as features. This way, the model can learn to use the past values of the predictors to predict the future value of the target variable.\n",
    "\n",
    "In the case of hourly data and a prediction horizon of 24 hours, we would create a lagged dataset where each row contains the predictors and the target variable for a particular hour. The target variable for each row would be the value 24 hours in the future, and the predictors for each row would be the values of the predictors for the previous 24 hours. We would then use this lagged dataset to train our model to make predictions for the next 24 hours.\n",
    "\n",
    "By shifting the target feature forward by one period, we are effectively creating a dataset where each observation includes the past observations up to the previous period and the target variable value for the next period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543d0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create lagged dataset wit 24 lag features for each input feature\n",
    "def create_lagged_dataset(df):\n",
    "    # creating a copy of the dataframe\n",
    "    lagged_df = df.copy()\n",
    "    \n",
    "    # Adding lagged features for target variable\n",
    "    lagged_df['Day-ahead Price [EUR/MWh] BZN|NO1'] = lagged_df['Day-ahead Price [EUR/MWh] BZN|NO1'].shift(-1)\n",
    "    \n",
    "    # Dropping the last row containing NaN values\n",
    "    lagged_df.dropna(inplace=True)\n",
    "    \n",
    "    # Creating a dataframe with lagged features with 24 steps for each of the original features\n",
    "    lagged_df = pd.concat([lagged_df.shift(i) for i in range(24)], axis=1)\n",
    "    \n",
    "    # Removing the NaN rows that have been created in the beginning of the dataset\n",
    "    lagged_df.dropna(inplace=True)\n",
    "    \n",
    "    return lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35b7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lagged dataset for train and test dataset\n",
    "lagged_train = create_lagged_dataset(train)\n",
    "lagged_test = create_lagged_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6012b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target feature and the input features\n",
    "train_y = lagged_train['Day-ahead Price [EUR/MWh] BZN|NO1']\n",
    "train_x = lagged_train.drop(['Day-ahead Price [EUR/MWh] BZN|NO1'], axis=1)\n",
    "\n",
    "test_y = lagged_test['Day-ahead Price [EUR/MWh] BZN|NO1']\n",
    "test_x = lagged_test.drop(['Day-ahead Price [EUR/MWh] BZN|NO1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1f64d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error:             19.063733650729827\n",
      "Mean absolute percentage error:  4.092398365430864\n",
      "Mean squared error:              734.3968037854144\n",
      "Rood mean squared error:         27.099756526312454\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# Make predictions on the test data\n",
    "pred_y = model.predict(test_x)\n",
    "\n",
    "# Calculate the mean absolute error (MAE) between the predicted and actual values\n",
    "mae = mean_absolute_error(test_y, pred_y)\n",
    "print(\"Mean absolute error:            \", mae)\n",
    "\n",
    "# Calculate the mean absolute percentage error (MAE) between the predicted and actual values\n",
    "mape = mean_absolute_percentage_error(test_y, pred_y)\n",
    "print(\"Mean absolute percentage error: \", mape)\n",
    "\n",
    "# Calculating the mean squared error (MSE) between the predicted and actual values\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"Mean squared error:             \", mse)\n",
    "\n",
    "# Calculating the root mean squared error (RMSE) between the predicted and actual values\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"Rood mean squared error:        \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad09c96",
   "metadata": {},
   "source": [
    "### NB! this is direct copy, needs to be rewritten!\n",
    "In terms of MAPE, a commonly used benchmark is a value less than 10%. However, this can vary depending on the specific industry and application. For example, in finance, a MAPE less than 2% may be considered good.\n",
    "\n",
    "For RMSE, a good value depends on the scale of the data being analyzed. A common practice is to compare the RMSE to the range of the target variable. As a rough guideline, an RMSE that is less than 10% of the range of the target variable can be considered good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17dae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
