{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b87d25b",
   "metadata": {},
   "source": [
    "## Data aggregation of energy market prices in bidding zone NO1 (Norway Ã˜stlandet) and neighbouring zones for the year of 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb69a78",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5de126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies to aggregate dataset\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from functools import reduce # used to merge the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8d1fd",
   "metadata": {},
   "source": [
    "### Aggregation of pricing data\n",
    "Pricing data is of spot (day-ahead) market prices in the currency Euro per MWh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9f605",
   "metadata": {},
   "source": [
    "Importing price data from each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd79e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 4)\n",
      "(8760, 4)\n",
      "(8760, 4)\n",
      "(8760, 4)\n",
      "(8760, 4)\n"
     ]
    }
   ],
   "source": [
    "# reading price csv to dataframes\n",
    "prices_no1 = pd.read_csv(\"../datasets/prices/NO1 Day-ahead Prices_202201010000-202301010000.csv\")\n",
    "prices_no2 = pd.read_csv(\"../datasets/prices/NO2 Day-ahead Prices_202201010000-202301010000.csv\")\n",
    "prices_no3 = pd.read_csv(\"../datasets/prices/NO3 Day-ahead Prices_202201010000-202301010000.csv\")\n",
    "prices_no5 = pd.read_csv(\"../datasets/prices/NO5 Day-ahead Prices_202201010000-202301010000.csv\")\n",
    "prices_se3 = pd.read_csv(\"../datasets/prices/SE3 Day-ahead Prices_202201010000-202301010000.csv\")\n",
    "\n",
    "# creating list of price dataframes\n",
    "prices_dataframes = [prices_no1, prices_no2, prices_no3, prices_no5, prices_se3]\n",
    "\n",
    "# checking shape of each dataframe to see if all dataframes have the same number of rows\n",
    "# row length should be 24 * 365 = 8760\n",
    "for i in prices_dataframes:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067050c",
   "metadata": {},
   "source": [
    "We see that all dataframes contain the correct number of rows.\n",
    "\n",
    "Printing out first rows of each dataset to see the structure and content of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6202e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>Currency</th>\n",
       "      <th>BZN|NO1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2022 00:00 - 01.01.2022 01:00</td>\n",
       "      <td>129.30</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2022 01:00 - 01.01.2022 02:00</td>\n",
       "      <td>132.08</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2022 02:00 - 01.01.2022 03:00</td>\n",
       "      <td>111.44</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2022 03:00 - 01.01.2022 04:00</td>\n",
       "      <td>112.35</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2022 04:00 - 01.01.2022 05:00</td>\n",
       "      <td>113.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MTU (UTC)  Day-ahead Price [EUR/MWh] Currency  \\\n",
       "0  01.01.2022 00:00 - 01.01.2022 01:00                     129.30      EUR   \n",
       "1  01.01.2022 01:00 - 01.01.2022 02:00                     132.08      EUR   \n",
       "2  01.01.2022 02:00 - 01.01.2022 03:00                     111.44      EUR   \n",
       "3  01.01.2022 03:00 - 01.01.2022 04:00                     112.35      EUR   \n",
       "4  01.01.2022 04:00 - 01.01.2022 05:00                     113.90      EUR   \n",
       "\n",
       "   BZN|NO1  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_no1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5edabdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>Currency</th>\n",
       "      <th>BZN|NO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2022 00:00 - 01.01.2022 01:00</td>\n",
       "      <td>129.30</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2022 01:00 - 01.01.2022 02:00</td>\n",
       "      <td>132.08</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2022 02:00 - 01.01.2022 03:00</td>\n",
       "      <td>111.44</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2022 03:00 - 01.01.2022 04:00</td>\n",
       "      <td>112.35</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2022 04:00 - 01.01.2022 05:00</td>\n",
       "      <td>113.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MTU (UTC)  Day-ahead Price [EUR/MWh] Currency  \\\n",
       "0  01.01.2022 00:00 - 01.01.2022 01:00                     129.30      EUR   \n",
       "1  01.01.2022 01:00 - 01.01.2022 02:00                     132.08      EUR   \n",
       "2  01.01.2022 02:00 - 01.01.2022 03:00                     111.44      EUR   \n",
       "3  01.01.2022 03:00 - 01.01.2022 04:00                     112.35      EUR   \n",
       "4  01.01.2022 04:00 - 01.01.2022 05:00                     113.90      EUR   \n",
       "\n",
       "   BZN|NO2  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_no2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371621b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>Currency</th>\n",
       "      <th>BZN|NO3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2022 00:00 - 01.01.2022 01:00</td>\n",
       "      <td>41.33</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2022 01:00 - 01.01.2022 02:00</td>\n",
       "      <td>42.18</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2022 02:00 - 01.01.2022 03:00</td>\n",
       "      <td>44.37</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2022 03:00 - 01.01.2022 04:00</td>\n",
       "      <td>37.67</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2022 04:00 - 01.01.2022 05:00</td>\n",
       "      <td>39.70</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MTU (UTC)  Day-ahead Price [EUR/MWh] Currency  \\\n",
       "0  01.01.2022 00:00 - 01.01.2022 01:00                      41.33      EUR   \n",
       "1  01.01.2022 01:00 - 01.01.2022 02:00                      42.18      EUR   \n",
       "2  01.01.2022 02:00 - 01.01.2022 03:00                      44.37      EUR   \n",
       "3  01.01.2022 03:00 - 01.01.2022 04:00                      37.67      EUR   \n",
       "4  01.01.2022 04:00 - 01.01.2022 05:00                      39.70      EUR   \n",
       "\n",
       "   BZN|NO3  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_no3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4f2009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>Currency</th>\n",
       "      <th>BZN|NO5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2022 00:00 - 01.01.2022 01:00</td>\n",
       "      <td>129.30</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2022 01:00 - 01.01.2022 02:00</td>\n",
       "      <td>132.08</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2022 02:00 - 01.01.2022 03:00</td>\n",
       "      <td>111.44</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2022 03:00 - 01.01.2022 04:00</td>\n",
       "      <td>112.35</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2022 04:00 - 01.01.2022 05:00</td>\n",
       "      <td>113.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MTU (UTC)  Day-ahead Price [EUR/MWh] Currency  \\\n",
       "0  01.01.2022 00:00 - 01.01.2022 01:00                     129.30      EUR   \n",
       "1  01.01.2022 01:00 - 01.01.2022 02:00                     132.08      EUR   \n",
       "2  01.01.2022 02:00 - 01.01.2022 03:00                     111.44      EUR   \n",
       "3  01.01.2022 03:00 - 01.01.2022 04:00                     112.35      EUR   \n",
       "4  01.01.2022 04:00 - 01.01.2022 05:00                     113.90      EUR   \n",
       "\n",
       "   BZN|NO5  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_no5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa7002e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>Currency</th>\n",
       "      <th>BZN|SE3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2022 00:00 - 01.01.2022 01:00</td>\n",
       "      <td>41.33</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2022 01:00 - 01.01.2022 02:00</td>\n",
       "      <td>42.18</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2022 02:00 - 01.01.2022 03:00</td>\n",
       "      <td>44.37</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2022 03:00 - 01.01.2022 04:00</td>\n",
       "      <td>37.67</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2022 04:00 - 01.01.2022 05:00</td>\n",
       "      <td>39.70</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MTU (UTC)  Day-ahead Price [EUR/MWh] Currency  \\\n",
       "0  01.01.2022 00:00 - 01.01.2022 01:00                      41.33      EUR   \n",
       "1  01.01.2022 01:00 - 01.01.2022 02:00                      42.18      EUR   \n",
       "2  01.01.2022 02:00 - 01.01.2022 03:00                      44.37      EUR   \n",
       "3  01.01.2022 03:00 - 01.01.2022 04:00                      37.67      EUR   \n",
       "4  01.01.2022 04:00 - 01.01.2022 05:00                      39.70      EUR   \n",
       "\n",
       "   BZN|SE3  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_se3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cdf61",
   "metadata": {},
   "source": [
    "#### preperation for merging of the price data from the different zones:\n",
    "The common column we will merge the data based on is the date time column \"MTU (UTC)\". The column currency is redundant since the column that holds price already includes it in the column name. The currency column can therefore be dropped. The datasets have a colum name for which zone the data is from, but does not include any data for each entry. This information can be added to the column name for price and the column for zone can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a54a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming price columns\n",
    "prices_no1 = prices_no1.rename(columns={'Day-ahead Price [EUR/MWh]': 'Day-ahead Price [EUR/MWh] BZN|NO1'})\n",
    "prices_no2 = prices_no2.rename(columns={'Day-ahead Price [EUR/MWh]': 'Day-ahead Price [EUR/MWh] BZN|NO2'})\n",
    "prices_no3 = prices_no3.rename(columns={'Day-ahead Price [EUR/MWh]': 'Day-ahead Price [EUR/MWh] BZN|NO3'})\n",
    "prices_no5 = prices_no5.rename(columns={'Day-ahead Price [EUR/MWh]': 'Day-ahead Price [EUR/MWh] BZN|NO5'})\n",
    "prices_se3 = prices_se3.rename(columns={'Day-ahead Price [EUR/MWh]': 'Day-ahead Price [EUR/MWh] BZN|SE3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b90540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping redundant columns\n",
    "prices_no1= prices_no1.drop(['Currency', 'BZN|NO1'], axis=1)\n",
    "prices_no2= prices_no2.drop(['Currency', 'BZN|NO2'], axis=1)\n",
    "prices_no3= prices_no3.drop(['Currency', 'BZN|NO3'], axis=1)\n",
    "prices_no5= prices_no5.drop(['Currency', 'BZN|NO5'], axis=1)\n",
    "prices_se3= prices_se3.drop(['Currency', 'BZN|SE3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6da0987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO1</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO2</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO3</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO5</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|SE3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2022 00:00 - 01.01.2022 01:00</td>\n",
       "      <td>129.30</td>\n",
       "      <td>129.30</td>\n",
       "      <td>41.33</td>\n",
       "      <td>129.30</td>\n",
       "      <td>41.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2022 01:00 - 01.01.2022 02:00</td>\n",
       "      <td>132.08</td>\n",
       "      <td>132.08</td>\n",
       "      <td>42.18</td>\n",
       "      <td>132.08</td>\n",
       "      <td>42.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2022 02:00 - 01.01.2022 03:00</td>\n",
       "      <td>111.44</td>\n",
       "      <td>111.44</td>\n",
       "      <td>44.37</td>\n",
       "      <td>111.44</td>\n",
       "      <td>44.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2022 03:00 - 01.01.2022 04:00</td>\n",
       "      <td>112.35</td>\n",
       "      <td>112.35</td>\n",
       "      <td>37.67</td>\n",
       "      <td>112.35</td>\n",
       "      <td>37.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2022 04:00 - 01.01.2022 05:00</td>\n",
       "      <td>113.90</td>\n",
       "      <td>113.90</td>\n",
       "      <td>39.70</td>\n",
       "      <td>113.90</td>\n",
       "      <td>39.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MTU (UTC)  Day-ahead Price [EUR/MWh] BZN|NO1  \\\n",
       "0  01.01.2022 00:00 - 01.01.2022 01:00                             129.30   \n",
       "1  01.01.2022 01:00 - 01.01.2022 02:00                             132.08   \n",
       "2  01.01.2022 02:00 - 01.01.2022 03:00                             111.44   \n",
       "3  01.01.2022 03:00 - 01.01.2022 04:00                             112.35   \n",
       "4  01.01.2022 04:00 - 01.01.2022 05:00                             113.90   \n",
       "\n",
       "   Day-ahead Price [EUR/MWh] BZN|NO2  Day-ahead Price [EUR/MWh] BZN|NO3  \\\n",
       "0                             129.30                              41.33   \n",
       "1                             132.08                              42.18   \n",
       "2                             111.44                              44.37   \n",
       "3                             112.35                              37.67   \n",
       "4                             113.90                              39.70   \n",
       "\n",
       "   Day-ahead Price [EUR/MWh] BZN|NO5  Day-ahead Price [EUR/MWh] BZN|SE3  \n",
       "0                             129.30                              41.33  \n",
       "1                             132.08                              42.18  \n",
       "2                             111.44                              44.37  \n",
       "3                             112.35                              37.67  \n",
       "4                             113.90                              39.70  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging the price data into one dataframe on the date time column 'MTU (UTC)'\n",
    "price_data_frames = [prices_no1, prices_no2, prices_no3, prices_no5, prices_se3]\n",
    "prices = reduce(lambda left, right: pd.merge(left,right, on=['MTU (UTC)']), price_data_frames)\n",
    "\n",
    "# printing out the 5 first rows resulting dataframe\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52623143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTU (UTC)</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO1</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO2</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO3</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|NO5</th>\n",
       "      <th>Day-ahead Price [EUR/MWh] BZN|SE3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>31.12.2022 19:00 - 31.12.2022 20:00</td>\n",
       "      <td>123.61</td>\n",
       "      <td>123.61</td>\n",
       "      <td>23.82</td>\n",
       "      <td>123.61</td>\n",
       "      <td>11.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>31.12.2022 20:00 - 31.12.2022 21:00</td>\n",
       "      <td>121.09</td>\n",
       "      <td>121.09</td>\n",
       "      <td>23.93</td>\n",
       "      <td>121.09</td>\n",
       "      <td>14.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>31.12.2022 21:00 - 31.12.2022 22:00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>23.75</td>\n",
       "      <td>120.00</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>31.12.2022 22:00 - 31.12.2022 23:00</td>\n",
       "      <td>119.98</td>\n",
       "      <td>119.98</td>\n",
       "      <td>23.56</td>\n",
       "      <td>119.98</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>31.12.2022 23:00 - 01.01.2023 00:00</td>\n",
       "      <td>119.32</td>\n",
       "      <td>119.32</td>\n",
       "      <td>23.35</td>\n",
       "      <td>119.32</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                MTU (UTC)  Day-ahead Price [EUR/MWh] BZN|NO1  \\\n",
       "8755  31.12.2022 19:00 - 31.12.2022 20:00                             123.61   \n",
       "8756  31.12.2022 20:00 - 31.12.2022 21:00                             121.09   \n",
       "8757  31.12.2022 21:00 - 31.12.2022 22:00                             120.00   \n",
       "8758  31.12.2022 22:00 - 31.12.2022 23:00                             119.98   \n",
       "8759  31.12.2022 23:00 - 01.01.2023 00:00                             119.32   \n",
       "\n",
       "      Day-ahead Price [EUR/MWh] BZN|NO2  Day-ahead Price [EUR/MWh] BZN|NO3  \\\n",
       "8755                             123.61                              23.82   \n",
       "8756                             121.09                              23.93   \n",
       "8757                             120.00                              23.75   \n",
       "8758                             119.98                              23.56   \n",
       "8759                             119.32                              23.35   \n",
       "\n",
       "      Day-ahead Price [EUR/MWh] BZN|NO5  Day-ahead Price [EUR/MWh] BZN|SE3  \n",
       "8755                             123.61                              11.57  \n",
       "8756                             121.09                              14.89  \n",
       "8757                             120.00                               9.94  \n",
       "8758                             119.98                               4.84  \n",
       "8759                             119.32                               2.01  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the last 5 rows of the resulting dataframe\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3be30b",
   "metadata": {},
   "source": [
    "We can se that the datetime of the first and last rows in the dataset are correct. we also want to check if the dataframe still have the correct number of rows to se if the merge was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63e9f785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out shape of dataframe\n",
    "prices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759fe60",
   "metadata": {},
   "source": [
    "The prices dataframe has the correct number of rows (8760) so the aggregation of the price datasets have been successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af833f9",
   "metadata": {},
   "source": [
    "### Aggregation of load data\n",
    "The load data contains data about the power consumption in each zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4e087",
   "metadata": {},
   "source": [
    "Importing load data from each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_no1 = pd.read_csv(\"../datasets/load/NO1 Total Load - Day Ahead _ Actual_202201010000-202301010000.csv\")\n",
    "load_no2 = pd.read_csv(\"../datasets/load/NO2 Total Load - Day Ahead _ Actual_202201010000-202301010000.csv\")\n",
    "load_no3 = pd.read_csv(\"../datasets/load/NO3 Total Load - Day Ahead _ Actual_202201010000-202301010000.csv\")\n",
    "load_no5 = pd.read_csv(\"../datasets/load/NO5 Total Load - Day Ahead _ Actual_202201010000-202301010000.csv\")\n",
    "load_se3 = pd.read_csv(\"../datasets/load/SE3 Total Load - Day Ahead _ Actual_202201010000-202301010000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb78a3",
   "metadata": {},
   "source": [
    "Printing out first rows of each dataset to see the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cde040",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_no1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cf27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_no2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_no3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_no5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_se3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48168ced",
   "metadata": {},
   "source": [
    "#### preperation for merging of the load data from the different zones:\n",
    "The common values we will merge the data based on is the date time column \"Time (CET/CEST)\", however this column is named \"MTU (CET/CEST)\" in the prices dataset. The time column will be renamed to \"MTU (CET/CEST)\" so that the datasets can be merged. The column \"Day-ahead Total Load Forecast\" is redundant since we have the actual total load, so the forecast column will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping redundant columns\n",
    "load_no1 = load_no1.drop(['Day-ahead Total Load Forecast [MW] - BZN|NO1'], axis=1)\n",
    "load_no2 = load_no2.drop(['Day-ahead Total Load Forecast [MW] - BZN|NO2'], axis=1)\n",
    "load_no3 = load_no3.drop(['Day-ahead Total Load Forecast [MW] - BZN|NO3'], axis=1)\n",
    "load_no5 = load_no5.drop(['Day-ahead Total Load Forecast [MW] - BZN|NO5'], axis=1)\n",
    "load_se3 = load_se3.drop(['Day-ahead Total Load Forecast [MW] - BZN|SE3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming time columns\n",
    "load_no1 = load_no1.rename(columns={'Time (CET/CEST)': 'MTU (CET/CEST)'})\n",
    "load_no2 = load_no2.rename(columns={'Time (CET/CEST)': 'MTU (CET/CEST)'})\n",
    "load_no3 = load_no3.rename(columns={'Time (CET/CEST)': 'MTU (CET/CEST)'})\n",
    "load_no5 = load_no5.rename(columns={'Time (CET/CEST)': 'MTU (CET/CEST)'})\n",
    "load_se3 = load_se3.rename(columns={'Time (CET/CEST)': 'MTU (CET/CEST)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the load data into one dataframe on the date time column 'MTU (CET/CEST)'\n",
    "load_data_frames = [load_no1, load_no2, load_no3, load_no5, load_se3]\n",
    "loads = reduce(lambda left, right: pd.merge(left,right, on=['MTU (CET/CEST)']), load_data_frames)\n",
    "\n",
    "# printing out the resulting dataframe\n",
    "loads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd882c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle missing values: NB! Bytt til det endelige datasettet, itte det for prices!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f674d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking data for missing values, if any\n",
    "prices.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which row is missing values\n",
    "null_data = prices[prices.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13eba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd58f0",
   "metadata": {},
   "source": [
    "This row is created as a result of the move from winter time to summer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df7443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e1205e",
   "metadata": {},
   "source": [
    "### Aggregation of energy generation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8028b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_generation_no1 = pd.read_csv(\"../datasets/wind_solar_fossil_biomass_and_others/NO1 Actual Generation per Production Type_202201010000-202301010000.csv\")\n",
    "actual_generation_no2 = pd.read_csv(\"../datasets/wind_solar_fossil_biomass_and_others/NO2 Actual Generation per Production Type_202201010000-202301010000.csv\")\n",
    "actual_generation_no3 = pd.read_csv(\"../datasets/wind_solar_fossil_biomass_and_others/NO3 Actual Generation per Production Type_202201010000-202301010000.csv\")\n",
    "actual_generation_no5 = pd.read_csv(\"../datasets/wind_solar_fossil_biomass_and_others/NO5 Actual Generation per Production Type_202201010000-202301010000.csv\")\n",
    "actual_generation_se3 = pd.read_csv(\"../datasets/wind_solar_fossil_biomass_and_others/SE3 Actual Generation per Production Type_202201010000-202301010000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_generation_no1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31db664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming every column to have zones instead of using a column for 'Area'\n",
    "actual_generation_no1.columns = ['Area','MTU (CET/CEST)','Biomass - BZN|NO1', 'Fossil Brown coal/Lignite - BZN|NO1', 'Fossil Coal-derived gas - BZN|NO1', 'Fossil Gas - BZN|NO1', 'Fossil Hard coal - BZN|NO1', 'Fossil Oil - BZN|NO1', 'Fossil Oil shale - BZN|NO1', 'Fossil Peat - BZN|NO1', 'Geothermal - BZN|NO1', 'Hydro Pumped Storage Aggregated- BZN|NO1', 'Hydro Pumped Storage Consumption - BZN|NO1', 'Hydro Run-of-river and poundage - BZN|NO1', 'Hydro Water Reservoir - BZN|NO1', 'Marine - BZN|NO1', 'Nuclear - BZN|NO1', 'Other - BZN|NO1', 'Other renewable - BZN|NO1', 'Solar - BZN|NO1', 'Waste - BZN|NO1', 'Wind Offshore - BZN|NO1', 'Wind Onshore - BZN|NO1']\n",
    "actual_generation_no2.columns = ['Area','MTU (CET/CEST)','Biomass - BZN|NO2', 'Fossil Brown coal/Lignite - BZN|NO2', 'Fossil Coal-derived gas - BZN|NO2', 'Fossil Gas - BZN|NO2', 'Fossil Hard coal - BZN|NO2', 'Fossil Oil - BZN|NO2', 'Fossil Oil shale - BZN|NO2', 'Fossil Peat - BZN|NO2', 'Geothermal - BZN|NO2', 'Hydro Pumped Storage Aggregated- BZN|NO2', 'Hydro Pumped Storage Consumption - BZN|NO2', 'Hydro Run-of-river and poundage - BZN|NO1', 'Hydro Water Reservoir - BZN|NO2', 'Marine - BZN|NO2', 'Nuclear - BZN|NO2', 'Other - BZN|NO2', 'Other renewable - BZN|NO2', 'Solar - BZN|NO2', 'Waste - BZN|NO2', 'Wind Offshore - BZN|NO2', 'Wind Onshore - BZN|NO2']\n",
    "actual_generation_no3.columns = ['Area','MTU (CET/CEST)','Biomass - BZN|NO3', 'Fossil Brown coal/Lignite - BZN|NO3', 'Fossil Coal-derived gas - BZN|NO3', 'Fossil Gas - BZN|NO3', 'Fossil Hard coal - BZN|NO3', 'Fossil Oil - BZN|NO3', 'Fossil Oil shale - BZN|NO3', 'Fossil Peat - BZN|NO3', 'Geothermal - BZN|NO3', 'Hydro Pumped Storage Aggregated- BZN|NO3', 'Hydro Pumped Storage Consumption - BZN|NO3', 'Hydro Run-of-river and poundage - BZN|NO3', 'Hydro Water Reservoir - BZN|NO3', 'Marine - BZN|NO3', 'Nuclear - BZN|NO3', 'Other - BZN|NO3', 'Other renewable - BZN|NO3', 'Solar - BZN|NO3', 'Waste - BZN|NO3', 'Wind Offshore - BZN|NO3', 'Wind Onshore - BZN|NO3']\n",
    "actual_generation_no5.columns = ['Area','MTU (CET/CEST)','Biomass - BZN|NO5', 'Fossil Brown coal/Lignite - BZN|NO5', 'Fossil Coal-derived gas - BZN|NO5', 'Fossil Gas - BZN|NO5', 'Fossil Hard coal - BZN|NO5', 'Fossil Oil - BZN|NO5', 'Fossil Oil shale - BZN|NO5', 'Fossil Peat - BZN|NO5', 'Geothermal - BZN|NO5', 'Hydro Pumped Storage Aggregated- BZN|NO5', 'Hydro Pumped Storage Consumption - BZN|NO5', 'Hydro Run-of-river and poundage - BZN|NO5', 'Hydro Water Reservoir - BZN|NO5', 'Marine - BZN|NO5', 'Nuclear - BZN|NO5', 'Other - BZN|NO5', 'Other renewable - BZN|NO5', 'Solar - BZN|NO5', 'Waste - BZN|NO5', 'Wind Offshore - BZN|NO5', 'Wind Onshore - BZN|NO5']\n",
    "actual_generation_se3.columns = ['Area','MTU (CET/CEST)','Biomass - BZN|SE3', 'Fossil Brown coal/Lignite - BZN|SE3', 'Fossil Coal-derived gas - BZN|SE3', 'Fossil Gas - BZN|SE3', 'Fossil Hard coal - BZN|SE3', 'Fossil Oil - BZN|SE3', 'Fossil Oil shale - BZN|SE3', 'Fossil Peat - BZN|SE3', 'Geothermal - BZN|SE3', 'Hydro Pumped Storage Aggregated- BZN|SE3', 'Hydro Pumped Storage Consumption - BZN|SE3', 'Hydro Run-of-river and poundage - BZN|SE3', 'Hydro Water Reservoir - BZN|SE3', 'Marine - BZN|SE3', 'Nuclear - BZN|SE3', 'Other - BZN|SE3', 'Other renewable - BZN|SE3', 'Solar - BZN|SE3', 'Waste - BZN|SE3', 'Wind Offshore - BZN|SE3', 'Wind Onshore - BZN|SE3']\n",
    "actual_generation_no1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping area because we keep the zone name in the column name\n",
    "actual_generation_no1 = actual_generation_no1.drop(['Area'], axis=1)\n",
    "actual_generation_no2 = actual_generation_no2.drop(['Area'], axis=1)\n",
    "actual_generation_no3 = actual_generation_no3.drop(['Area'], axis=1)\n",
    "actual_generation_no5 = actual_generation_no5.drop(['Area'], axis=1)\n",
    "actual_generation_se3 = actual_generation_se3.drop(['Area'], axis=1)\n",
    "actual_generation_no1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc56399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one dataframe from the 5 dataframes for each zone\n",
    "actual_generation_dataframes = [actual_generation_no1, actual_generation_no2, actual_generation_no3, actual_generation_no5, actual_generation_se3]\n",
    "actual_generation = reduce(lambda left, right: pd.merge(left,right, on=['MTU (CET/CEST)']), actual_generation_dataframes)\n",
    "\n",
    "# printing out the resulting dataframe\n",
    "actual_generation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41740a",
   "metadata": {},
   "source": [
    "We have alot of columns which are used in other nations and zones that are redundant to us because there is no power generation from these sources in the zones we are looking at. Therefore, we select only the columns which keep information about power generation in each zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only relevant columns\n",
    "actual_generation_selected = actual_generation[['MTU (CET/CEST)', 'Biomass - BZN|NO1', 'Fossil Gas - BZN|NO1', 'Hydro Run-of-river and poundage - BZN|NO1_x', 'Hydro Water Reservoir - BZN|NO1', 'Waste - BZN|NO1', 'Wind Onshore - BZN|NO1', 'Fossil Gas - BZN|NO2', 'Hydro Pumped Storage Aggregated- BZN|NO2', 'Hydro Pumped Storage Consumption - BZN|NO2', 'Hydro Run-of-river and poundage - BZN|NO1_y', 'Hydro Water Reservoir - BZN|NO2', 'Waste - BZN|NO2', 'Wind Onshore - BZN|NO2', 'Hydro Pumped Storage Aggregated- BZN|NO3', 'Hydro Pumped Storage Consumption - BZN|NO3', 'Hydro Run-of-river and poundage - BZN|NO3', 'Hydro Water Reservoir - BZN|NO3', 'Other - BZN|NO3', 'Other renewable - BZN|NO3', 'Waste - BZN|NO3', 'Wind Onshore - BZN|NO3', 'Fossil Gas - BZN|NO5', 'Hydro Pumped Storage Aggregated- BZN|NO5', 'Hydro Pumped Storage Consumption - BZN|NO5', 'Hydro Run-of-river and poundage - BZN|NO5', 'Hydro Water Reservoir - BZN|NO5', 'Waste - BZN|NO5', 'Fossil Gas - BZN|SE3', 'Hydro Water Reservoir - BZN|SE3', 'Nuclear - BZN|SE3', 'Other - BZN|SE3', 'Solar - BZN|SE3', 'Wind Onshore - BZN|SE3']].copy()\n",
    "# printing the head of the resulting dataframe\n",
    "actual_generation_selected.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a337189",
   "metadata": {},
   "source": [
    "We can see that the formatting of the datetime interval includes (CET/CEST) in the actual values. This extra information will ned to be removed so they mach the other datasets, and can be merged on the time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing (CET/CEST) and trailing whitespace from datetime values in column 'MTU (CET/CEST)'\n",
    "actual_generation_selected['MTU (CET/CEST)'] = actual_generation_selected['MTU (CET/CEST)'].map(lambda x: x.rstrip(')(/CEST').strip())\n",
    "\n",
    "# printing out resulting dataset\n",
    "actual_generation_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc914e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_generation_selected.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af64ff",
   "metadata": {},
   "source": [
    "### Data Aggregation for import and export\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a5e4f",
   "metadata": {},
   "source": [
    "We want to concatenate data for cross border physical flow between NO1 and neighbouring zones(NO2,NO3,NO5,SE3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f47b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing import export datasets\n",
    "import_export_no1_no2 = pd.read_csv(\"../datasets/import_and_export/NO1-NO2 Import export Cross-Border Physical Flow_202201010000-202301010000.csv\")\n",
    "import_export_no1_no3 = pd.read_csv(\"../datasets/import_and_export/NO1-NO3 Import export Cross-Border Physical Flow_202201010000-202301010000.csv\")\n",
    "import_export_no1_no5 = pd.read_csv(\"../datasets/import_and_export/NO1-NO5 Import export Cross-Border Physical Flow_202201010000-202301010000.csv\")\n",
    "import_export_no1_se3 = pd.read_csv(\"../datasets/import_and_export/NO1-SE3 Import export Cross-Border Physical Flow_202201010000-202301010000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16599315",
   "metadata": {},
   "source": [
    "NO1_NO2_import_export.head()\n",
    "In other data files the time unite is MTU (CET/CEST), this is not teh case for import and export data. To be consistent Time (CET/CEST) is changed to MTU (CET/CEST). To make it clear that 'BZN|NO2 > BZN|NO1 [MW]' shows the cross border physical flow , CBF is used as an abbreviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0636f9",
   "metadata": {},
   "source": [
    "Printing out first rows of each dataset to see the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_export_no1_no2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_export_no1_no3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256de327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_export_no1_no5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7802eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_export_no1_se3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749a4f3",
   "metadata": {},
   "source": [
    "We see that the time column in the import export datasets is named \"Time(CET/CEST)\" while in the other datasets, the time column is named \"MTU (CET/CET)\". The time column will be renamed to \"MTU (CET/CEST)\" so that the datasets can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b667151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_export_no1_no2.rename(columns = {'Time (CET/CEST)':'MTU (CET/CEST)', 'BZN|NO2 > BZN|NO1 [MW]' : 'CBF BZN|NO2 > BZN|NO1 [MW]', 'BZN|NO1 > BZN|NO2 [MW]' : 'CBF BZN|NO1 > BZN|NO2 [MW]'}, inplace = True)\n",
    "import_export_no1_no3.rename(columns = {'Time (CET/CEST)':'MTU (CET/CEST)', 'BZN|NO3 > BZN|NO1 [MW]' : 'CBF BZN|NO3 > BZN|NO1 [MW]', 'BZN|NO1 > BZN|NO3 [MW]' : 'CBF BZN|NO1 > BZN|NO3 [MW]'}, inplace = True)\n",
    "import_export_no1_no5.rename(columns = {'Time (CET/CEST)':'MTU (CET/CEST)', 'BZN|NO5 > BZN|NO1 [MW]' : 'CBF BZN|NO5 > BZN|NO1 [MW]', 'BZN|NO1 > BZN|NO5 [MW]' : 'CBF BZN|NO1 > BZN|NO5 [MW]'}, inplace = True)\n",
    "import_export_no1_se3.rename(columns = {'Time (CET/CEST)':'MTU (CET/CEST)', 'BZN|SE3 > BZN|NO1 [MW]' : 'CBF BZN|SE3 > BZN|NO1 [MW]', 'BZN|NO1 > BZN|SE3 [MW]' : 'CBF BZN|NO1 > BZN|SE3 [MW]'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce09ca",
   "metadata": {},
   "source": [
    "Merging all dataframes for import and export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the import export datasets\n",
    "import_export_no1_neighbours_dataframes = [import_export_no1_no2, import_export_no1_no3, import_export_no1_no5, import_export_no1_se3]\n",
    "import_export_no1_neighbours = reduce(lambda left, right: pd.merge(left,right, on=['Time (UTC)']), import_export_no1_neighbours_dataframes)\n",
    "\n",
    "# printing out the 5 first rows of the resulting dataframe\n",
    "import_export_no1_neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58606dcb",
   "metadata": {},
   "source": [
    "### Aggregation of Water Reservoirs and Hydro Storage Plants\n",
    "\n",
    "The water reservoir dataset is measured with a weekly frequency while the other datasets are measured hourly. In order to make the data match frequency of measurements of the other datasets, we will need to up sample the data thorough interpolation.  We will first map the weekly measurement to the first hour of each week, and then interpolate the intermediate measurement. In order to interpolate the measurements of the last week, we will add the measurement for the first week of the succeeding year (2023) to the dataset. this measurement  will be dropped from the final dataset. Additionally, the first week of 2022 starts on january 3. 2022, so in order to get the data for the first two days we add the dataset for the last week of 2021. We will use spline interpolation to add smoothness to the interpolated curve, which will be more representative of water level fluctuations than a linear interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322dcc01",
   "metadata": {},
   "source": [
    "Reading in water levels as CSV with pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in main datasets (2022)\n",
    "water_level_NO1 = pd.read_csv(\"../datasets/water_level/NO1_2022_Water_Reservoirs_and_Hydro_Storage_Plants_202201030000-202301020000.csv\")\n",
    "water_level_NO2 = pd.read_csv(\"../datasets/water_level/NO2_2022_Water_Reservoirs_and_Hydro_Storage Plants_202201030000-202301020000.csv\")\n",
    "water_level_NO3 = pd.read_csv(\"../datasets/water_level/NO3_2022_Water_Reservoirs_and_Hydro_Storage Plants_202201030000-202301020000.csv\")\n",
    "water_level_NO5 = pd.read_csv(\"../datasets/water_level/NO5_2022_Water_Reservoirs_and_Hydro_Storage Plants_202201030000-202301020000.csv\")\n",
    "water_level_SE3 = pd.read_csv(\"../datasets/water_level/SE3_2022_Water_Reservoirs_and_Hydro_Storage Plants_202201030000-202301020000.csv\")\n",
    "\n",
    "# Reading in only the last week of 2021\n",
    "water_level_NO1_2021 = pd.read_csv(\"../datasets/water_level/NO1_2021_Water Reservoirs and Hydro Storage Plants_202101040000-202201030000.csv\", skiprows=range(1, 52))\n",
    "water_level_NO2_2021 = pd.read_csv(\"../datasets/water_level/NO2_2021_Water Reservoirs and Hydro Storage Plants_202101040000-202201030000.csv\", skiprows=range(1, 52))\n",
    "water_level_NO3_2021 = pd.read_csv(\"../datasets/water_level/NO3_2021_Water Reservoirs and Hydro Storage Plants_202101040000-202201030000.csv\", skiprows=range(1, 52))\n",
    "water_level_NO5_2021 = pd.read_csv(\"../datasets/water_level/NO5_2021_Water Reservoirs and Hydro Storage Plants_202101040000-202201030000.csv\", skiprows=range(1, 52))\n",
    "water_level_SE3_2021 = pd.read_csv(\"../datasets/water_level/SE3_2021_Water Reservoirs and Hydro Storage Plants_202101040000-202201030000.csv\", skiprows=range(1, 52))\n",
    "\n",
    "# Reading in only the first week of 2023\n",
    "water_level_NO1_2023 = pd.read_csv(\"../datasets/water_level/NO1_2023_Water Reservoirs and Hydro Storage Plants_202301020000-202401010000.csv\", nrows=1)\n",
    "water_level_NO2_2023 = pd.read_csv(\"../datasets/water_level/NO2_2023_Water Reservoirs and Hydro Storage Plants_202301020000-202401010000.csv\", nrows=1)\n",
    "water_level_NO3_2023 = pd.read_csv(\"../datasets/water_level/NO3_2023_Water Reservoirs and Hydro Storage Plants_202301020000-202401010000.csv\", nrows=1)\n",
    "water_level_NO5_2023 = pd.read_csv(\"../datasets/water_level/NO5_2023_Water Reservoirs and Hydro Storage Plants_202301020000-202401010000.csv\", nrows=1)\n",
    "water_level_SE3_2023 = pd.read_csv(\"../datasets/water_level/SE3_2023_Water Reservoirs and Hydro Storage Plants_202301020000-202401010000.csv\", nrows=1)\n",
    "\n",
    "# Renaming the Week datapoint for all 2023 datasets because they are originally called \"week 1\" which would create confusion in the data\n",
    "water_level_NO1_2023.at[0, 'Week'] = 'Week 53'\n",
    "water_level_NO2_2023.at[0, 'Week'] = 'Week 53'\n",
    "water_level_NO3_2023.at[0, 'Week'] = 'Week 53'\n",
    "water_level_NO5_2023.at[0, 'Week'] = 'Week 53'\n",
    "water_level_SE3_2023.at[0, 'Week'] = 'Week 53'\n",
    "\n",
    "# Getting 'Week 52' from 2021 datasets\n",
    "water_level_NO1_2021.at[0, 'Week'] = 'Week 0'\n",
    "water_level_NO2_2021.at[0, 'Week'] = 'Week 0'\n",
    "water_level_NO3_2021.at[0, 'Week'] = 'Week 0'\n",
    "water_level_NO5_2021.at[0, 'Week'] = 'Week 0'\n",
    "water_level_SE3_2021.at[0, 'Week'] = 'Week 0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47084655",
   "metadata": {},
   "source": [
    "Checking to see if we have correctly selected the last week of 2021 and first week of 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the dataframe containes the first week of  2023\n",
    "water_level_NO1_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc7ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the dataframe containes the last week of  2021\n",
    "water_level_NO1_2021.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be8499",
   "metadata": {},
   "source": [
    "Concatinating the datasets and ignoring the index to create a new index. The concatination happens in the order of how they are written in pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating the dataset to add the first week of 2023 to the 2022 datasets. ignore index ignores the index number of the row in 2023 and gives it a new after being \"appended\"\n",
    "water_level_NO1 = pd.concat([water_level_NO1_2021, water_level_NO1, water_level_NO1_2023], ignore_index= True, axis=0)\n",
    "water_level_NO2 = pd.concat([water_level_NO2_2021, water_level_NO2, water_level_NO2_2023], ignore_index= True, axis=0)\n",
    "water_level_NO3 = pd.concat([water_level_NO3_2021, water_level_NO3, water_level_NO3_2023], ignore_index= True, axis=0)\n",
    "water_level_NO5 = pd.concat([water_level_NO5_2021 ,water_level_NO5, water_level_NO5_2023], ignore_index= True, axis=0)\n",
    "water_level_SE3 = pd.concat([water_level_SE3_2021, water_level_SE3, water_level_SE3_2023], ignore_index= True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341814d",
   "metadata": {},
   "source": [
    "Testing to see if the concatination is succesfull by looking at the first and last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out first 5 rows of the resulting dataset to see if the last week\n",
    "# of 2021 was added\n",
    "water_level_NO1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out last 5 rows of the resulting dataset to see if the first week\n",
    "# of 2023 was added\n",
    "water_level_NO1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d32dcb",
   "metadata": {},
   "source": [
    "We can see that the extra weeks have been added correctly and can merge the datasets from the different zones into a larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a50280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes\n",
    "water_level_dataframes = [water_level_NO1, water_level_NO2, water_level_NO3, water_level_NO5, water_level_SE3]\n",
    "water_level_dataframes = reduce(lambda left, right: pd.merge(left,right, on=['Week']), water_level_dataframes)\n",
    "\n",
    "# printing out the 5 first rows of the resulting dataframe\n",
    "water_level_dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f33793",
   "metadata": {},
   "source": [
    "We will now convert the week numbers into the datetime corresponding with the first day of each week, starting on 27th of december 2021 and ending on the 2nd of January 2023. This is done with pd.date_range which returns a fixed frequency DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ba3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2021-12-27'\n",
    "end_date = '2023-01-02'\n",
    "week_date_timeframe = pd.DataFrame(pd.date_range(start=start_date, end=end_date, freq='7D'))\n",
    "week_date_timeframe.rename(columns={0: 'Week_start_date'}, inplace=True)\n",
    "week_date_timeframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb503ef",
   "metadata": {},
   "source": [
    "Now that we have a dataset containing corresponding datetimes to the weekly water levels, we can now join the two dataframes, and we can drop the 'Week' column as it is no longer of any use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the dataframes week_start_date and water_level_dataframes\n",
    "joined_water_week = pd.concat([week_date_timeframe, water_level_dataframes], axis=1)\n",
    "joined_water_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the week column\n",
    "joined_water_week.drop('Week', axis=1, inplace=True)\n",
    "\n",
    "# printing out 5 first rows of the resulting dataframe\n",
    "joined_water_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69053ae",
   "metadata": {},
   "source": [
    "Setting 'Week_start_date' as the index so that the whole dataframe can be treated as a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d213d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 'Week_start_date' as the index\n",
    "joined_water_week.set_index('Week_start_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the resulting index\n",
    "joined_water_week.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d82fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the 5 first rows of the resulting dataframe\n",
    "joined_water_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27367798",
   "metadata": {},
   "source": [
    "Upsampling the data by changing the frequency from a 7 day frequency to a hour based one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uppsampling joined_water_week dataframe to an hourly frequency\n",
    "joined_water_week = joined_water_week.asfreq('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out 5 first rows of the resulting dataframe\n",
    "joined_water_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out 5 last rows of the resulting dataframe\n",
    "joined_water_week.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960ccf2",
   "metadata": {},
   "source": [
    "We can see that the data has been upsampled, and we can interpolate the data. We will interpolate with spline itnerpolation to generate polynomeal  datapoints while requiering a lower polynomeal degree.The classical approach is to use polynomials of exactly degree 3 - cubic splines. source: Erwin Kreyszig (2005). Advanced Engineering Mathematics (9 ed.). Wiley. p. 816. ISBN 9780471488859."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcc59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing cubic spline interpolation (3rd degree polynomeal)\n",
    "interpolated_df = joined_water_week.interpolate(method='spline', order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the 5 first rows of the interpolated dataframe\n",
    "interpolated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the 5 last rows of the interpolated dataframe\n",
    "interpolated_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data for missing values, if any\n",
    "interpolated_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8d60d",
   "metadata": {},
   "source": [
    "The data above includes the timestamps for last week of 2021 and first week of 2023. To make the water level dataframe mach the other datafames we will filter out the data from the year 2021 and 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b49967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the data from year 2021 and 2023\n",
    "filtering_interpolation_df = interpolated_df.loc[(interpolated_df.index >= '2022-01-01 00:00:00')\n",
    "                   & (interpolated_df.index <= '2022-12-31 23:00:00')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a16b3",
   "metadata": {},
   "source": [
    "The other datasets have a numerical index, and the time as a feature, we therefore reset the index to mach the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7dcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index\n",
    "water_reservoir = filtering_interpolation_df\n",
    "water_reservoir = water_reservoir.reset_index()\n",
    "water_reservoir.rename(columns={'Week_start_date': 'MTU (CET/CEST)'})\n",
    "water_reservoir.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c56ea98",
   "metadata": {},
   "source": [
    "We now have the finished water_reservoir dataframe which we can merge with the other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out 5 first rows of the finished water_reservoir dataframe\n",
    "water_reservoir.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d99d6",
   "metadata": {},
   "source": [
    "### Aggregating all subdatasets\n",
    "Now that we have aggregated each of the subdatasets, we can merge them together into a larger dataset that can be used to train time series electricity price prediction models on. we will wait with adding the water_reservoir untill the time-range column 'MTU (CET/CEST)' of the other datasets have been converted to datetime columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging prices, loads, actual_generation_selected and\n",
    "# import_export_no1_neighbours dataframes on the date time\n",
    "# column 'MTU (CET/CEST)'\n",
    "\n",
    "# creating a list of dataframes\n",
    "no1_data_frames = [\n",
    "    prices,\n",
    "    loads,\n",
    "    actual_generation_selected,\n",
    "    import_export_no1_neighbours]\n",
    "\n",
    "# merging dataframes\n",
    "no1 = reduce(lambda left, right: pd.merge(\n",
    "    left,right, on=['MTU (CET/CEST)']), no1_data_frames)\n",
    "\n",
    "# printing out the resulting dataframe\n",
    "no1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(no1_data_frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68cc441",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(prices))\n",
    "print(len(loads))\n",
    "print(len(actual_generation_selected))\n",
    "print(len(import_export_no1_neighbours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27797a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(prices, loads, on=['MTU (CET/CEST)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(actual_generation_selected, import_export_no1_neighbours, on=['MTU (CET/CEST)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673210b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
